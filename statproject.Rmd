---
title: "| ![](logo.png){width=2.3in} \\vspace{0.2in} \n  Daily Electricity Price and Demand Analysis\\vspace{0.2in} "
subtitle: " Statistical learning Project\\vspace{0.4in}"
date: "July 19, 2022"
author: 
- Mojtaba Amini 
- Javier Alberto Bernal Sigala 
- Carmen Rocio Ortiz Benitez 
- Saeed Soufeh



output: pdf_document


params:
  term: "July 2022"
---

```{=tex}
\newpage
\tableofcontents
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (!require(dplyr)) {
    install.packages("dplyr")
    require(dplyr)
}

if (!require(rmarkdown)) {
    install.packages("rmarkdown")
    require(rmarkdown)
}

if (!require(pillar)) {
    install.packages("pillar")
    require(pillar)
}

if (!require(corrplot)) {
    install.packages("corrplot")
    require(corrplot)
}

if (!require(tidyverse)) {
    install.packages("tidyverse")
    require(tidyverse)
}
if (!require(Amelia)) {
    install.packages("Amelia")
    require(Amelia)
}
if (!require(naniar)) {
    install.packages("naniar")
    require(naniar)
}
if (!require(Hmisc)) {
    install.packages("Hmisc")
    require(Hmisc)
}

if (!require(data.table)) {
    install.packages("data.table")
    require(data.table)
}

if (!require(fastDummies)) {
    install.packages("fastDummies")
    require(fastDummies)
}
if (!require(hrbrthemes)) {
    install.packages("hrbrthemes")
    require(hrbrthemes)
}
if (!require(viridis)) {
    install.packages("viridis")
    require(viridis)
}
if (!require(forcats)) {
    install.packages("forcats")
    require(forcats)
}
if (!require(patchwork)) {
    install.packages("patchwork")
    require(patchwork)
}
if (!require(magrittr)) {
    install.packages("magrittr")
    require(magrittr)
}
if (!require(multipanelfigure)) {
    install.packages("multipanelfigure")
    require(multipanelfigure)
}
if (!require(PerformanceAnalytics)) {
    install.packages("PerformanceAnalytics")
    require(PerformanceAnalytics)
}
if (!require(pROC)) {
    install.packages("pROC")
    require(pROC)
}
if (!require(knitr)) {
    install.packages("knitr")
    require(knitr)
}
if (!require(boot)) {
    install.packages("boot")
    require(boot)
}

library(patchwork)
library(magrittr)
library(multipanelfigure)
library(PerformanceAnalytics)

library(rmarkdown)
library(pillar)
library(ggplot2)

library(dplyr)
library(corrplot)
library(tidyverse)
library(Amelia)
library(naniar)
library(Hmisc)
library(data.table)
library(fastDummies)
library(hrbrthemes)
library(viridis)
library(forcats)
library(pROC)
library(knitr)
library(boot)

#library(PerformanceAnalytics)
```

# 1 Introduction

Victoria is the second smallest state in surface, and the second most populous state in Australia, with a population of 6.7 million (in 2020) it is the state with the highest density. This state maintains an electricity consumption that corresponds to 21% of the entire country, especially in the capital, Melbourne (5 million). Aware that electricity is essential for people, in the following work we will try to draw conclusions about the demand and prices of electricity consumption of the inhabitants of Victoria using observation and statistical inference methods.

Statistical inference is defined as the process of using data analysis to infer on the properties of an underlying distribution, in other contexts the concept of inference is used as "learning" or "training". Regression methods are a type of inference in which models are used to establish the relationship between a target variable and its predictor variables, these targets can belong to a normal distribution as in linear regression, to even a binomial as in logistic regression.

Thus, the aim of this project is to build a regression model to predict demand that takes into account the factors that influence it the most, and secondly building a prediction model with enough accuracy and efficiency. Additionally, we will build a logistic regression model to classify whether RRP (Recommended Retail Price) will be high or low.

# 1.1 Objectives

* Explore the data in depth in order to understand relations between variables and their behavior.
* Build a regression model to predict electricity demand.
* Build a logistic regression model to classify the RRP as above or below the median.

# 2 Data Collection

This dataset has 2,106 observations and 14 variables, and it is a record from January 2015 to October 2020 of daily electricity price and demand in the state of Victoria, Australia. It is available publicly (in <https://www.kaggle.com/datasets/aramacus/electricity-demand-in-victoria-australia>). Daily electricity may depend on different factors such as rainfall, solar exposure, whether it was a school day, etc; and also the correlations between them. It is clear to see how any of these variables could be meaningful in our analysis.

## 2.1 Variables description

The variables present on our dataset are:

-   date: the date of the recording;
-   demand: total daily electricity demand in MWh (megawatt hour);
-   RRP: a recommended retail price in AUD\$ / MWh (Australian Dollars per MWh);
-   demand_pos_RRP: total daily demand at positive RRP in MWh;
-   RRP_positive: averaged positive RRP, weighted by the corresponding daily demand in AUD\$ / MWh (Australian Dollars per MWh);
-   demand_neg_RRP: total daily demand at negative RRP in MWh (megawatt hour);
-   RRP_negative: average negative RRP, weighted by the corresponding daily demand in AUD\$ / MWh (Australian Dollars per MWh);
-   frac_at_neg_RRP: fraction of the day when the demand was traded at negative RRP;
-   min_temperature: minimum temperature during the day in Celsius;
-   max_temperature: maximum temperature during the day in Celsius;
-   solar_exposure: total daily sunlight energy in MJ/m\^2 (megajoule per square meter);
-   rainfall: rainfall during the day in mm;
-   school_day: whether students were at school on that day;
-   holiday: whether the day was a holiday.

It is worth noting that the RRP is calculated considering different components such as wholesale costs, network charges, and retail margin, all information which we do not have access too. Furthermore, the RRP and its related features (demand_pos_RRP, RRP_positive, demand_neg_RRP, RRP_negative, frac_at_neg_RRP) will depend strongly on demand and on each other, and that is why we choose not to consider them when building our model.


```{r}
data <- read.csv(file = "complete_dataset.csv")
summary(data)
```
In terms of continuous variables, the values from the RRP 3rd quantile and the maximum differ excessively, which suggests that this might be an outlier. Furthermore, there are only 4 null values and they located in the solar_exposure and rainfall columns. Distribution of demand itself does not vary too much, with values ranging from around 85,000 MWh to 170,000 MWh.


## 2.2 Data preparation

We check for "duplicate" rows and find there are none.

```{r}
cat("Cheking for duplicated rows...", "The dataset has", sum(duplicated(data)), "duplicated rows.\n")

```
In order to ease the analysis, we proceed to drop the find the missing values and remove them.

```{r}
#see the missing values
vis_miss(data)

#drop missing solar_exposure
data <- data[!is.na(data$solar_exposure),]

#drop missing rainfall
data <- data[!is.na(data$rainfall),]
```

Next, we transform the date column from char to date, the min and max temperature into one combined mean temperature, and the holiday and school_day columns from char to categorical (binary).

```{r}

#convert the date
data$date <- as.POSIXct(data$date)

#add the mean temperature variable
data$mean_temperature <- (data$max_temperature + data$min_temperature)/2

#turn the holidays to binary
data$holiday <- as.factor(data$holiday)
data <- data %>% 
    mutate(holiday = recode(holiday, 
                      "N" = FALSE, 
                      "Y" = TRUE))

#turn the school_day to binary
data$school_day <- as.factor(data$school_day) 

data <- data %>% 
    mutate(school_day = recode(school_day, 
                      "N" = FALSE, 
                      "Y" = TRUE))

```


# 3 Exploratory Data Analysis (EDA)

In this section we will use some visual tools to discover hidden trends and patterns in the dataset that can help us build an accurate and efficient model to make predictions on daily electricity demand.

We start by doing some general analysis on demand, since this is what our model will be centered around.


```{r}
options(repr.plot.width=7, repr.plot.height=5)
ggplot(data, aes(x= demand/1000)) +
geom_histogram(aes(y =..density..), fill="pink", color="black", alpha=0.6) +
geom_density(color= "blue", size =0.8)+
geom_vline(aes(xintercept= mean(demand/1000)), color="blue",linetype="dashed", size=1) +
geom_vline(aes(xintercept= median(demand/1000)), color="red",linetype="dashed", size=1) +

labs(x ="Energy Demand x 1000", y="Count")
```


The histogram above shows that the distribution of the energy demand is almost symmetrical with the mean and median values both at around 120,000 Mwh.


```{r}
deamnd_plot <- ggplot(data, aes(x = demand)) +
geom_boxplot(fill = "pink") +
geom_point(aes(x= mean(demand), y=0), color="blue")

deamnd_plot
```

Furthermore, from the box-plot shown above, we can see that the energy demand has a longer tail on the right side, with all the outliers being there. Since the outliers are few and do not differ too much from the values at the end of the right tail, we keep them.

We move on to do some analysis on RRP.

```{r}

options(repr.plot.width=7, repr.plot.height=5)
ggplot(data, aes(x= RRP)) +
geom_histogram(aes(y =..density..), fill="pink", color="black", alpha=0.6) +
geom_density(color= "blue", size =0.8)+
geom_vline(aes(xintercept= mean(RRP)), color="blue",linetype="dashed", size=1) +
geom_vline(aes(xintercept= median(RRP)), color="red",linetype="dashed", size=1) +

labs(x ="RRP", y="Count")

```

The above histogram of the RRP shows an extremely long right tail, especially when compared to the left tail. This indicates the presence of outliers, so we decide to further investigate this.


```{r}


#OUTLIARS
Q <- quantile(data$RRP)
data_ol <- subset(data, data$RRP >= Q[4]+1.5*(Q[4]-Q[2]) | data$RRP<= Q[2]-1.5*(Q[4]-Q[2]))

dim(data_ol)

```
Indeed, there are 28 outliers for the RRP variable. These values differ excessively from the rest, which indicates there may have been an error when collecting the data. Furthermore, since the values are so great they will have a big impact other variables, thus we decide to remove these outliers.


```{r}
#WITHOUT
data <- subset(data, data$RRP <= Q[4]+1.5*(Q[4]-Q[2]) & data$RRP>= Q[2]-1.5*(Q[4]-Q[2]))

RRP_plot <- ggplot(data, aes(x = RRP)) +
geom_boxplot(fill = "pink") +
geom_point(aes(x= mean(RRP), y=0), color="blue")

RRP_plot
```

After removing the outliers, the RRP distribution is almost symmetrical, but the right tail is still longer, as seen in the box-plot above. We can derive much more information from this subset.


```{r}

options(repr.plot.width=7, repr.plot.height=5)
ggplot(data, aes(x= RRP)) +
geom_histogram(aes(y =..density..), fill="pink", color="black", alpha=0.6) +
geom_density(color= "blue", size =0.8)+
geom_vline(aes(xintercept= mean(RRP)), color="blue",linetype="dashed", size=1) +
geom_vline(aes(xintercept= median(RRP)), color="red",linetype="dashed", size=1) +

labs(x ="RRP", y="Count")

```

As for the histogram, without the outliers, RRP is shown to have a bimodal distribution, with the most frequent values in the RRP axis around 40 and 85. This histogram is much more informative than the previous one.

We proceed to analyse the relationship of some categorical variables with electricity demand.

```{r}
bplot2 <- barplot(table(data$school_day),
            main="School days",
            ylab="Count",
            density=10
            )

```
In the graph above, we can see that the data is unbalanced.

```{r}

bplot1 <- barplot(table(data$holiday),
            main="Holiday",
            ylab="Count",
            density=10
            )

```

In the above case, the data is even more severely unbalanced than the school days.

```{r}
p1 <- ggplot(data, aes(x=demand)) +
geom_histogram(aes(y=..density..),color="black", fill="pink", bins=40) +
geom_density(color="blue") +
geom_vline(aes(xintercept= mean(demand)), color="blue", linetype="dashed",size=1) +
geom_vline(aes(xintercept= median(demand)), color="red", linetype="dashed",size=1)


p2 <- ggplot(data, aes(x = demand)) +
geom_boxplot(fill = "pink") +
geom_point(aes(x= mean(demand), y=0), color="blue")


p3 <- ggplot(data, aes(x=holiday, y=demand, group=holiday)) +
  geom_boxplot(fill="pink") +
  stat_summary(fun=mean, geom="point", color="blue") +
  coord_flip()


p4 <- ggplot(data, aes(x=school_day, y=demand, group=school_day)) +
  geom_boxplot(fill="pink") +
  stat_summary(fun=mean, geom="point", color="blue") +
  coord_flip() 



p1+p2 +p3+ p4
```

In the plots above, we can see that the distribution of electricity demand on its own is almost symmetrical. However, when plotted with relation to "holiday", the mean is much lower when the values are True, and also the variance is significantly smaller. As for demand plotted with respect to "school_day", demand is generally higher on school days.



```{r}
options(repr.plot.width=15, repr.plot.height=5)
sd.colors <- c("#999999", "#E69F00")

p1 <- ggplot(data[data$holiday == FALSE,], aes(x=demand, y= ..density..))+
geom_histogram(fill=sd.colors[1],bins=20, alpha=.5)+
geom_density(color=sd.colors[1])+
labs(x = "Demand on Usual Days")

p2 <- ggplot(data[data$holiday == TRUE,], aes(x=demand, y= ..density..))+
geom_histogram(fill=sd.colors[2],bins=20, alpha=.5)+
geom_density(color=sd.colors[2])+
labs(x = "Demand on Holidays")

p3 <- ggplot(data, aes(x = demand, fill = holiday)) +
geom_density(alpha = 0.5) +
scale_fill_manual(values=sd.colors)+
labs(x = "Total Demand")



figure1 <- multi_panel_figure(columns = 2, rows = 2, panel_label_type = "none")
figure1 %<>%
  fill_panel(p1, column = 1, row = 1) %<>%
  fill_panel(p2, column = 2, row = 1) %<>%
  fill_panel(p3, column = 1:2, row = 2)
figure1
```

As seen in the density graphs above, the difference in distributions in demand for holidays and non-holidays is evident. Mean demand on holidays is much lower than on non-holidays, and the variance is also smaller. For non-holidays, daily demand values are less concentrated.


```{r}
options(repr.plot.width=15, repr.plot.height=5)
sd.colors <- c("#999999", "#E69F00")

p1 <- ggplot(data[data$school_day == FALSE,], aes(x=demand, y= ..density..))+
geom_histogram(fill=sd.colors[1],bins=20, alpha=.5)+
geom_density(color=sd.colors[1])+
labs(x = "Demand on School Days")

p2 <- ggplot(data[data$school_day == TRUE,], aes(x=demand, y= ..density..))+
geom_histogram(fill=sd.colors[2],bins=20, alpha=.5)+
geom_density(color=sd.colors[2])+
labs(x = "Demand on Usual Days")

p3 <- ggplot(data, aes(x = demand , fill = school_day)) +
geom_density(alpha = 0.5) +
scale_fill_manual(values=sd.colors)+
labs(x = "Total Demand")


figure1 <- multi_panel_figure(columns = 2, rows = 2, panel_label_type = "none")

figure1 %<>%
  fill_panel(p1, column = 1, row = 1) %<>%
  fill_panel(p2, column = 2, row = 1) %<>%
  fill_panel(p3, column = 1:2, row = 2)
figure1
```

Regarding the school days feature, the differences are not as dramatic as with the holidays. Mean demand on school days is a little higher, but the variance does not differ by a lot.

Next, we visualize the evolution of RRP and demand throughout the years.

```{r}
coeff <- 2000
df2015 <- subset(data, date < "2016-01-01 00:00:00")
df2016 <- subset(data, date < "2017-01-01 00:00:00" & date >= "2016-01-01 00:00:00")
df2017 <- subset(data, date < "2018-01-01 00:00:00" & date >= "2017-01-01 00:00:00")
df2018 <- subset(data, date < "2019-01-01 00:00:00" & date >= "2018-01-01 00:00:00")
df2019 <- subset(data, date < "2020-01-01 00:00:00" & date >= "2019-01-01 00:00:00")
df2020 <- subset(data, date < "2021-01-01 00:00:00" & date >= "2020-01-01 00:00:00")

p2015 <- ggplot(df2015, aes(x=date)) +
  geom_line( aes(y=RRP), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "RRP",sec.axis = sec_axis(~.*coeff, 
                                                      name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2015 dates")
p2016 <- ggplot(df2016, aes(x=date)) +
  geom_line( aes(y=RRP), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "RRP",sec.axis = sec_axis(~.*coeff, 
                                                      name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2016 dates")
p2017 <- ggplot(df2017, aes(x=date)) +
  geom_line( aes(y=RRP), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "RRP",sec.axis = sec_axis(~.*coeff, 
                                                      name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2017 dates")
p2018 <- ggplot(df2018, aes(x=date)) +
  geom_line( aes(y=RRP), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "RRP",sec.axis = sec_axis(~.*coeff, 
                                                      name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2018 dates")
p2019 <- ggplot(df2019, aes(x=date)) +
  geom_line( aes(y=RRP), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "RRP",sec.axis = sec_axis(~.*coeff, 
                                                      name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2019 dates")
p2020 <- ggplot(df2020, aes(x=date)) +
  geom_line( aes(y=RRP), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "RRP",sec.axis = sec_axis(~.*coeff, 
                                                      name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2020 dates")

pfull <- ggplot(data, aes(x=date)) +
  geom_line( aes(y=RRP), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "RRP",sec.axis = sec_axis(~.*coeff, 
                                                      name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"),
        axis.title.y = element_text(size = 7))



figure1 <- multi_panel_figure(columns = 3, rows = 3, panel_label_type = "none")
figure1 %<>%
  fill_panel(p2015, column = 1, row = 1) %<>%
  fill_panel(p2016, column = 2, row = 1) %<>%
  fill_panel(p2017, column = 3, row = 1) %<>%
  fill_panel(p2018, column = 1, row = 2) %<>%
  fill_panel(p2019, column = 2, row = 2) %<>%
  fill_panel(p2020, column = 3, row = 2) %<>%
  fill_panel(pfull, column = 1:3, row = 3)
figure1
```
The above graphs show that while demand does not fluctuate much over the years, RRP does shift considerably during and throughout the years. There there was a notable peak in RRP around 2017 that lasted until almost 2020, when it went down again. Furthermore,
it is shown that around the time Covid-19 related measures were put in place (March 2020), behavior of demand did not change. Although we are interested in further investigating this, the available dataset did not provide any useful insights to do it.

Next, we investigate the relations between temperature (min and max) and the other features, starting with RRP.

```{r}


p1 <- ggplot(data, aes(x=min_temperature, y=RRP)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Min Temperature x RRP") +
theme(plot.title = element_text(size=10))

p2 <- ggplot(data, aes(x=max_temperature, y=RRP)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Max Temperature x RRP") +
theme(plot.title = element_text(size=10))


options(repr.plot.width=5, repr.plot.height=60)
layout <- "A \n B"
p1+p2 + plot_layout(design = layout)

```

We can see that the relations of min and max temperature with RRP are extremely similar. Then, we move on to check the relations with demand.

```{r}


p1 <- ggplot(data, aes(x=min_temperature, y=demand)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Min Tmperature x Demand") +
theme(plot.title = element_text(size=10))

p2 <- ggplot(data, aes(x=max_temperature, y=demand)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Max Tmperature x Demand") +
theme(plot.title = element_text(size=10))


options(repr.plot.width=5, repr.plot.height=60)
layout <- "A \n B "
p1+p2+p3 + plot_layout(design = layout)

```

The similarity in relations here is a bit less than with RRP, but still existent. We proceed to check the relation between temperatures and solar exposure.

```{r}

p1 <- ggplot(data, aes(x=min_temperature, y=solar_exposure)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Min Temperature x Solar Exposure") +
theme(plot.title = element_text(size=10))

p2 <- ggplot(data, aes(x=max_temperature, y=solar_exposure)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Max Temperature x Solar_exposure") +
theme(plot.title = element_text(size=10))


options(repr.plot.width=5, repr.plot.height=60)
layout <- "A \n B"
p1+p2 + plot_layout(design = layout)

```

Here, they are extremely similar again. Finally, we check the relations between mean temperature with min and max temperature.


```{r}

p1 <- ggplot(data, aes(x=min_temperature, y=mean_temperature)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Min Temperature x Mean Temperature") +
theme(plot.title = element_text(size=10))

p2 <- ggplot(data, aes(x=max_temperature, y=mean_temperature)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Max Temperature x Mean Temperature") +
theme(plot.title = element_text(size=10))


options(repr.plot.width=5, repr.plot.height=60)
layout <- "A \n B"
p1+p2 + plot_layout(design = layout)

```

Again, the relations are very similar. From this analyses we conclude that the min and max temperature can be combined into one single mean temperature variable.

We move on to visualize the evolution of mean temperature and demand throughout the years.


```{r}

p2015 <- ggplot(df2015, aes(x=date)) +
  geom_line( aes(y=mean_temperature), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "mean temperature[°C]",sec.axis = sec_axis(~.*coeff, name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2015 dates")
p2016 <- ggplot(df2016, aes(x=date)) +
  geom_line( aes(y=mean_temperature), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "mean temperature[°C]",sec.axis = sec_axis(~.*coeff, name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2016 dates")
p2017 <- ggplot(df2017, aes(x=date)) +
  geom_line( aes(y=mean_temperature), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "mean temperature[°C]",sec.axis = sec_axis(~.*coeff, name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2017 dates")
p2018 <- ggplot(df2018, aes(x=date)) +
  geom_line( aes(y=mean_temperature), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "mean temperature[°C]",sec.axis = sec_axis(~.*coeff, name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2018 dates")
p2019 <- ggplot(df2019, aes(x=date)) +
  geom_line( aes(y=mean_temperature), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "mean temperature[°C]",sec.axis = sec_axis(~.*coeff, name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2019 dates")
p2020 <- ggplot(df2020, aes(x=date)) +
  geom_line( aes(y=mean_temperature), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "mean temperature[°C]",sec.axis = sec_axis(~.*coeff, name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))+
  labs(x = "2020 dates")

pfull <- ggplot(data, aes(x=date)) +
  geom_line( aes(y=mean_temperature), color = 'red') + 
  geom_line( aes(y=demand/coeff),color = 'blue') + 
  scale_y_continuous(name = "mean temperature[°C]",sec.axis = sec_axis(~.*coeff, name="Demand")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(size = 7),
        axis.line.y.right = element_line(color = "blue"),
        axis.line.y.left = element_line(color = "red"))


figure1 <- multi_panel_figure(columns = 3, rows = 3, panel_label_type = "none")
figure1 %<>%
  fill_panel(p2015, column = 1, row = 1) %<>%
  fill_panel(p2016, column = 2, row = 1) %<>%
  fill_panel(p2017, column = 3, row = 1) %<>%
  fill_panel(p2018, column = 1, row = 2) %<>%
  fill_panel(p2019, column = 2, row = 2) %<>%
  fill_panel(p2020, column = 3, row = 2) %<>%
  fill_panel(pfull, column = 1:3, row = 3)
figure1

```



From the above graph, it is clear that when mean temperature peaks, demand goes down and viceversa. This indicates that more electricity is used when the weather is colder.


We think that the behavior of demand may change depending on the seasons. To investigate this, we proceed to separate the data on seasons (summer, autumn, winter, spring) as categorical values.

```{r}
data$month<-as.numeric(format(data$date,"%m"))
data$season <- "summer"
data$season[data$month>2 & data$month<6] <- "autumn"
data$season[data$month>5 & data$month<9] <- "winter"
data$season[data$month>8 & data$month<12] <- "spring"
data$season<-factor(data$season,levels=c("summer","spring","winter","autumn"))
summary(data$season)
```

```{r}
options(repr.plot.width=15, repr.plot.height=10)
p1 <- ggplot(data, aes(x=season, y=RRP, group=season)) +
  geom_boxplot(fill="pink") +
  stat_summary(fun=mean, geom="point", color="blue") 

p2 <- ggplot(data, aes(x=RRP, y=..count.., fill=season))+
geom_density(alpha=0.3)

figure1 <- multi_panel_figure(columns = 1, rows = 2, panel_label_type = "none")
figure1 %<>%
  fill_panel(p1, column = 1, row = 1) %<>%
  fill_panel(p2, column = 1, row = 2)
figure1

```

From the above graphs, we can see that RRP values are the highest in winter and the lowest in summer. As for spring and autumn, values don't differ a lot. Variance in all seasons is similar.

We continue to investigate the effect of the seasons, this time in the electricity demand.

```{r}
options(repr.plot.width=15, repr.plot.height=10)
p1 <- ggplot(data, aes(x=season, y=demand, group=season)) +
  geom_boxplot(fill="pink") +
  stat_summary(fun=mean, geom="point", color="blue") 

p2 <- ggplot(data, aes(x=demand, y=..count.., fill=season))+
geom_density(alpha=0.3)

figure1 <- multi_panel_figure(columns = 1, rows = 2, panel_label_type = "none")
figure1 %<>%
  fill_panel(p1, column = 1, row = 1) %<>%
  fill_panel(p2, column = 1, row = 2)
figure1

```

In the graphs shown above, it is clear that the demand on winter is higher than in the other seasons. Summer has the lowest demand comparatively, but it does not differ much from the spring and autumn ones. Variance of demand during summer is the highest. Based on these insights, we conclude that using seasons as a categorical value provides useful information, and continue to do so.

We move on to investigate the effect of rainfall in both electricity demand and RRP.

```{r}


p1 <- ggplot(data, aes(x=rainfall, y=demand)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Demand x rainfall") +
theme(plot.title = element_text(size=10))

p2 <- ggplot(data, aes(x=rainfall, y=RRP)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="RRP x rainfall") +
theme(plot.title = element_text(size=10))

options(repr.plot.width=5, repr.plot.height=60)
layout <- "A \n B"
p1+p2+plot_layout(design = layout)
```

The above graphs indicate that as rainfall increases, demand and RRP decrease, although not much. The shape of the graph also indicates that doing a transformation will be beneficial, so we proceed to investigate the behavior of the logarithm of rainfall and add 1, to avoid errors when the rainfall is 0.

```{r}

data$log_rainfall <- log(data$rainfall+1)

```

```{r}

p1 <- ggplot(data, aes(x=log_rainfall, y=demand)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Demand x log rainfall") +
theme(plot.title = element_text(size=10))

p2 <- ggplot(data, aes(x=log_rainfall, y=RRP)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="RRP x log rainfall") +
theme(plot.title = element_text(size=10))

options(repr.plot.width=5, repr.plot.height=60)
layout <- "A \n B"
p1+p2+plot_layout(design = layout)
```
From the above graphs, we can see the after the transformation of rainfall, the effect in demand and RRP is still not significant, especially for demand. RRP decreases very slightly as log rainfall increases.

Next, we plot some graphs to see the effect of solar exposure on demand.

```{r}


p1 <- ggplot(data, aes(x=solar_exposure, y=demand)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="Demand x solar exposure") +
theme(plot.title = element_text(size=10))

p2 <- ggplot(data, aes(x=solar_exposure, y=RRP)) +
geom_jitter(alpha=0.5, size=0.7) +
scale_color_manual("mediumorchid1") +
geom_rug() +
geom_smooth(method=lm, formula=y~x) +
labs(title="RRP x solar exposure") +
theme(plot.title = element_text(size=10))

options(repr.plot.width=5, repr.plot.height=60)
layout <- "A \n B"
p1+p2+plot_layout(design = layout)
```
As seen above, as solar exposure increases demand decreases. As for RRP, the effect of solar exposure is almost imperceptible.


Next, we check the correlation matrix in order to find potentially significant relations between variables. 

```{r}
data_copy <- copy(data)
options(repr.plot.width=7, repr.plot.height=7)
data_copy$holiday= as.numeric(data_copy$holiday)
data_copy$school_day = as.numeric(data_copy$school_day)
data_copy$date = as.numeric(data_copy$date)

numerical <- subset(data_copy, select = c(demand,
                                     RRP,
                                     mean_temperature,
                                     solar_exposure,
                                     rainfall,
                                     school_day,
                                     holiday
                                     ))

correlation <- cor(numerical)

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(correlation, method="color", col=col(200),
         type="upper",
         addCoef.col = "black",
         tl.col="black", tl.srt=45,
         sig.level = 0.01, insig = "blank",
         diag=FALSE,tl.cex=0.7, number.cex=0.6)
```

This correlation plot suggests that we start by analyzing the relation between demand and solar_exposure, and demand and holiday. The feature that has less correlation with demand is rainfall.


## 3.1 Variable statistics

In this part, we will test some hypotheses to further understand the effect of different variables on demand. From the previously performed EDA, we see that it is possible that the categorical variables have an effect on the electricity demand. In this section, we wish further investigate this.

### 3.1.1 Hypothesis 1

The equality of means of the demand on school days and non-school days is going to be examined. For this, we want to perform a t-test, and before checking the equality of the means, we have to check the equality of the variances. To do so, an F-test is going to be carried out first.

$\sigma_{school}$ is the standard deviation of demand for school days and $\sigma_{notschool}$ is the standard deviation for the other days.

* $H_{0}$: $\sigma_{school}$ $=$ $\sigma_{notschool}$
* $H_{1}$: $\sigma_{school}$ $\neq$ $\sigma_{notschool}$


```{r}

school_days <- data[data$school_day == TRUE,]$demand
no_school_days <- data[data$school_day == FALSE,]$demand

var.test(school_days, no_school_days , alternative="two.sided")
```

We cannot perform a t-test to analyze the equality of the mean, since we do not have evidence to conclude that the variances of demand on school day vs not school days are equal. This is not surprising, given that as seen in the EDA section, the data is very unbalanced.


### 3.1.2 Hypothesis 2

We want to examine the equality of means of the demand on holidays and non-holidays. As before, we have to check the equality of the variances before carrying out the t-test.

$\sigma_{holiday}$ is the standard deviation of demand for holidays and $\sigma_{notholiday}$ is the standard deviation for the other days.

* $H_{0}$: $\sigma_{holiday}$ $=$ $\sigma_{notholiday}$
* $H_{1}$: $\sigma_{holiday}$ $\neq$ $\sigma_{notholiday}$

```{r}
holidays <- data[data$holiday == TRUE,]$demand
no_holidays <- data[data$holiday == FALSE,]$demand

var.test(holidays, no_holidays , alternative="two.sided")
```

Again, we cannot conclude that the variances of the two populations are equal and thus we cannot perform a t-test. Once more, this is not surprising, since in this case the data is even more severely unbalanced as previously seen on the EDA phase.


# 4 Model Data & Analysis

## 4.1 Linear Regression Model

### 4.1.1 Numerical variables

In this section we will consider the effect of numerical variables on electricity demand. As we know from the correlation matrix performed during the EDA, the solar exposure (solar_exposure) has high correlation with demand. So, we start by building a linear regression model with only this variable and continue by adding one variable at a time. Performance in this section will be analyzed in terms of BIC ((Bayesian Information Criterion) and Adjusted $R^{2}$.

We start by building a model with only the solar exposure variable.

```{r}
mod.num0 <- lm(data=data, demand ~ solar_exposure)
summary(mod.num0)
```

```{r}

BIC(mod.num0)

```

```{r}

# Diagnostic
par(mfrow=c(2,2))
plot(mod.num0)

```
The behavior of residuals seen above are admissible. We proceed to check the shape of this model.

```{r}
ggplot(data, aes(x = solar_exposure, y = demand)) +
geom_point() +
stat_smooth(method = "lm", formula = y ~ x) +
labs(x = 'solar_exposure', y = 'demand')


```
From the above plot, we can see that our model may benefit by increasing the polynomial degree. After comparing different degree models, we find that the best performance is obtained by the fourth degree one, as confirmed by performing the following cross validation.

```{r}
#polynomial for solar exposure
set.seed(1)
cv.error.10.ex <- rep(0,10)
for (i in 1:10){
  glm.fit <- glm(demand~poly(solar_exposure,i),data=data)
  cv.error.10.ex[i] <- cv.glm(data,glm.fit,K=10)$delta[1]
}
cv.error.10.ex

expo.temp <- plot(1:10, cv.error.10.ex, type="b", xlab="degree", ylab="K-fold CV error for solar exposure")

expo.temp
```


```{r}
ggplot(data, aes(x = solar_exposure, y = demand)) +
geom_point() +
stat_smooth(method = "lm", formula = y ~ poly(x, 4)) +
labs(x = 'solar_exposure', y = 'demand')


```

```{r}
mod.num1 <- lm(data=data, demand ~ poly(solar_exposure, 4))
summary(mod.num1)
```

```{r}

BIC(mod.num1)

```

```{r}

# Diagnostic
par(mfrow=c(2,2))
plot(mod.num1)

```
The behavior of the model is acceptable, since residuals are distributed uniformly across the fitted values, and our model has constant variance.

From the above plots, we conclude that keeping the solar exposure feature can be useful and thus we keep the feature in our model.

Next, we evaluate the effect of adding mean temperature to the linear model.


```{r}
mod.num2 <- lm(data=data, demand ~ poly(solar_exposure, 4) + mean_temperature)
summary(mod.num2)

```
```{r}
BIC(mod.num2)

```

```{r}
# Diagnostic
par(mfrow=c(2,2))
plot(mod.num2)

```

For this model the behavior of residuals is still acceptable but BIC is a little worse. We proceed to check the behavior of the model with only the mean temperature variable in order to have a better idea of the effect of this variable.



```{r}

mod.num3 <- lm(data=data, demand ~ mean_temperature)
summary(mod.num3)

```

```{r}
BIC(mod.num3)

```

```{r}
# Diagnostic
par(mfrow=c(2,2))
plot(mod.num3)

```

The residual plot exhibits a U-shape, which indicates that the data is non-linear.

```{r}
ggplot(data, aes(x = mean_temperature, y = demand)) +
geom_point() +
stat_smooth(method = "lm", formula = y ~ x) +
labs(x = 'mean temperature', y = 'demand')


```

The behavior of mean temperature as seen above suggests that increasing the degree of the mean temperature variable can improve the model. By doing the cross validation, we see that the lowest error is achieved with degree four.

```{r}
#polynomial for mean_temperature
set.seed(1)
cv.error.10.tm <- rep(0,10)
for (i in 1:10){
  glm.fit <- glm(demand~poly(mean_temperature,i),data=data)
  cv.error.10.tm[i] <- cv.glm(data,glm.fit,K=10)$delta[1]
}
cv.error.10.tm

temp.pol = plot(1:10, cv.error.10.tm, type="b", xlab="degree", ylab="K-fold CV error for mean_temperature")

temp.pol

```

We produce the fourth degree model:

```{r}
ggplot(data, aes(x = mean_temperature, y = demand)) +
geom_point() +
stat_smooth(method = "lm", formula = y ~ poly(x, 4)) +
labs(x = 'mean temperature', y = 'demand')


```

```{r}

mod.num4 <- lm(data=data, demand ~ poly(mean_temperature, 4))
summary(mod.num4)

```

```{r}
BIC(mod.num4)

```

The BIC for this fourth degree model is better than for the first degree one. We also compared with the BIC for the second and third degree models, and this had the best performance.


```{r}
# Diagnostic
par(mfrow=c(2,2))
plot(mod.num4)

```

Behavior of the residuals is also better.

We proceed to add this new variable to the model and check the performance.

```{r}
mod.num5 <- lm(data=data, demand ~ poly(solar_exposure, 4) + poly(mean_temperature, 4))
summary(mod.num5)

```

```{r}
BIC(mod.num5)

```
With this model, the BIC improves.

```{r}
# Diagnostic
par(mfrow=c(2,2))
plot(mod.num5)

```
Residual behavior is also acceptable. Since the model behavior improved, we keep this fourth degree term and go on to add a variable that we previously examined on the EDA section, log_rainfall.

```{r}
mod.num6 <- lm(data=data, demand ~ poly(solar_exposure, 4) + 
                 poly(mean_temperature, 4) + log_rainfall)
summary(mod.num6)

```

```{r}
BIC(mod.num6)

```
By adding the rainfall feature to the model, BIC improves a little.

```{r}
# Diagnostic
par(mfrow=c(2,2))
plot(mod.num6)

```

Residual plots show an admissible behavior. Now, we check the behavior of the model with only the log_rainfall variable.


```{r}

mod.num7 <- lm(data=data, demand ~ log_rainfall)
summary(mod.num7)

```

```{r}
BIC(mod.num7)

```
```{r}
# Diagnostic
par(mfrow=c(2,2))
plot(mod.num7)

```

The "log_rainfall" does not have a big impact on the model, but we keep it for now and will further analyze and decide afterwards. We proceed to build a table to compare the BIC and Adjusted $R^{2}$ of the different models more easily.


```{r, echo=FALSE}

Variables_num <- c('solar exposure^4/mean temperature', 'solar exposure^4/mean temperature^4', 'solar exposure^4/mean temperature^4/log rainfall', 'solar exposure^4', 'solar exposure', 'mean temperature^4', 'mean temperature', 'log rainfall')
BIC_num <- c(45119.29, 44083.89, 44066.24, 45044.64, 45113.74, 44193.91, 45241.01, 45316.64)
Adjusted_R2_num<- c(0.1308, 0.4601, 0.4664, 0.131, 0.09287, 0.4234, -0.03545, -0.0003652)

tdf_num <- data.frame(Variables_num, BIC_num, Adjusted_R2_num)
kable(tdf_num, type='latex')


```

From the above table we can see that the model behavior does not improve much by adding log rainfall so we decide to remove this feature. Therefore, the resulting model has only the fourth degree solar exposure and mean temperature variables.


### 4.1.2 Adding categorical variables

Next, we build a model considering only the categorical variables. We start considering all three of them.

```{r}
mod.cat0 <- lm(demand ~ school_day + season + holiday, data=data)
summary(mod.cat0)

```

```{r}
summary(mod.cat0)$adj.r.squared

```

```{r}
BIC(mod.cat0)

```

```{r}
par(mfrow=c(2,2))
plot(mod.cat0)
```

Next, since they are not many, we consider all possible subsets of the variables to find the model which results in the best performance in terms of BIC and Adjusted $R^{2}$. We start with a combination of the school day and season features.

```{r}
mod.cat1 <- lm(demand ~ school_day + season , data=data)
summary(mod.cat1)

```

```{r}
summary(mod.cat1)$adj.r.squared

```

```{r}
BIC(mod.cat1)

```

Next, we combine the holiday and season features.

```{r}
mod.cat2 <- lm(demand ~ holiday + season , data=data)
summary(mod.cat2)

```

```{r}
summary(mod.cat2)$adj.r.squared

```

```{r}
BIC(mod.cat2)

```

Then, we try a combination of the holiday and school day features.

```{r}
mod.cat3 <- lm(demand ~ holiday + school_day , data=data)
summary(mod.cat3)

```

```{r}
summary(mod.cat3)$adj.r.squared

```

```{r}
BIC(mod.cat3)

```

We move on to consider only school day.

```{r}
mod.cat4 <- lm(demand ~ school_day , data=data)
summary(mod.cat4)

```

```{r}
summary(mod.cat4)$adj.r.squared

```

```{r}
BIC(mod.cat4)

```

Next, we only consider holiday.

```{r}
mod.cat5 <- lm(demand ~ holiday , data=data)
summary(mod.cat5)

```

```{r}
summary(mod.cat5)$adj.r.squared

```

```{r}
BIC(mod.cat5)

```

Finally, we consider only the season feature.

```{r}
mod.cat6 <- lm(demand ~ season , data=data)
summary(mod.cat6)

```

```{r}
summary(mod.cat6)$adj.r.squared

```

```{r}
BIC(mod.cat6)

```

```{r, echo=FALSE}

Variables_cat <- c('school day/season/holiday', 'school day/season', 'season/holiday', 'school day/holiday', 'school day', 'holiday', 'season')
BIC_cat <- c(44616.54, 44724.16, 44626.09, 45166.55, 45274.07, 45181.64, 44750.67)
Adjusted_R2_cat <- c(0.2953041, 0.2553871, 0.2897857, 0.07244284, 0.01995818, 0.0626738, 0.2433993)

tdf_cat <- data.frame(Variables_cat, BIC_cat, Adjusted_R2_cat)
kable(tdf_cat, type='latex')


```

After comparing the BIC and Adjusted $R^{2}$ for all the different models, we conclude that the best model performance is achieved when considering all three categorical variables. However, since during the exploratory phase we determined that the holiday feature is severely unbalanced, we remove it from our model and keep only the season and school day variables.


### 4.1.3 Unified model

Combining all the numerical and categorical variables we get the following model:

```{r}
mod.tot0 <- lm(demand ~ poly(solar_exposure, 4) + poly(mean_temperature, 4) +
                 season + school_day , data=data)
summary(mod.tot0)

```

```{r}

BIC(mod.tot0)

```

```{r}
par(mfrow=c(2,2))
plot(mod.tot0)

```
Behavior of the residuals is acceptable since they are distributed uniformly across the fitted values, and the model has constant variance. The BIC and Adjusted $R^{2}$ are better with respect to the all the previous models.


## 4.2 Logistic Regression

In this section we will build a logistic regression model in order to classify RRP as high or not, depending on whether it is above or below the median. To measure performance we will compare the different AUC (Area Under the Curve).


```{r}
attach(data)
data$month <- as.factor(data$month)


#add the high RRP column
data$high_RRP <- TRUE
data$high_RRP[data$RRP <= median(data$RRP)] <- FALSE

#split in validation and train sets
dt = sort(sample(nrow(data), nrow(data)*.7))
train<-data[dt,]
test<-data[-dt,]

train$source <- "train"
test$source<- "test"

toplot <- rbind(train,test) 

# create a dataset
high_RRP <- c(TRUE, TRUE, FALSE, FALSE )
condition <- c("train" , "test", "train", "test") 
value <- c(table(toplot$source, toplot$high_RRP)[2,2], table(toplot$source, toplot$high_RRP)[1,2], table(toplot$source, toplot$high_RRP)[2,1], table(toplot$source, toplot$high_RRP)[1,1])
toplot2 <- data.frame(high_RRP,condition,value)

# Grouped
ggplot(toplot2, aes(fill=condition, y=value, x=high_RRP)) + 
  geom_bar(position="dodge", stat="identity")

```

The sets were separated into 70% training and 30% validation, obtaining samples of the original set randomly. The TRUE and FALSE labels are equally balanced in the train and test sets. This is to be expected since the split was at the median.

### 4.2.1 Logistic Regression Using Seasons

For this first part, a model will be tested using the season variable, then it will be replaced by the month variable, in order to compare and select the best performance.

We will start by building an initial model using the variables "demand", "mean_temperature", "solar_exposure", the logarithm of "rainfall", "holiday", "season", that the EDA showed are the most descriptive for the RRP. Then, through a process of backward elimination, the variables that were making less contribution to the model will be simplified, observing the p-value and the deviance as criteria to obtain the best model.

We build the first model:

```{r}

logit.out1 <- glm(high_RRP ~ demand + mean_temperature + solar_exposure + log(rainfall +1) + holiday + school_day + season, data = train, family = binomial)

summary(logit.out1)
```

```{r}

logistic.prob <- predict(logit.out1, type="response")
roc.out <- roc(train$high_RRP, logistic.prob, levels=c(FALSE, TRUE))
plot(roc.out, print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
```

It can be understood that it is not possible to find a model with a high "true positive rate" and a low "false positive rate" to define the threshold as seen in the ROC (receiver operating characteristic curve. In any case, this process will continue.

Based on the P-values obtained from the previous model, we decide to remove the holiday feature, as it's the highest, and continue like this until significant changes in the deviance are obtained, which would indicate the end of this process


```{r}
logit.out2 <- glm(high_RRP ~ demand + mean_temperature + solar_exposure + log(rainfall +1) + school_day + season,data = train, family = binomial)
summary(logit.out2)
```



```{r}

logit.out3 <- glm(high_RRP ~ demand + mean_temperature + log(rainfall+1) + school_day + season, data = train, family = binomial)
summary(logit.out3)
```


```{r}
logit.out4 <- glm(high_RRP ~ demand + mean_temperature + school_day + season, data = train, family = binomial)

summary(logit.out4)
```

```{r}
logit.out5 <- glm(high_RRP ~ demand + school_day + season, data = train, family = binomial)

summary(logit.out5)
```

AUC improved but not by much.

Then, we try a model without considering the seasons:

```{r}
logit.out6 <- glm(high_RRP ~ demand + school_day ,data = train, family = binomial)

summary(logit.out6)
```

The second model contains the results without the holiday variable, in the following models the variables "solar_exposure", logarithm of "rainfall", "mean_temperature" and finally the seasons were removed consecutively. After removing the variable "mean_temperature", the deviance begins to have relatively significant changes, that is why the final model is the logit.out4 that contains: "demand", "mean_temperature", "school_day", and "season". 

In the following plot it is possible to see the AUC of the ROC to understand how much the discarding of the other variables has affected the model.

```{r}
logistic.prob <- predict(logit.out4, type="response")
roc.out <- roc(train$high_RRP, logistic.prob, levels=c(FALSE, TRUE))
plot(roc.out, print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
```

### 4.2.1 Logistic Regression Using Months

As an alternative, we try to see if we can increase the performance of the model by using the months variables instead of the seasons, repeating the same procedure above but skipping some steps.

We start by using all the variables.

```{r}
logit.out1 <- glm(high_RRP ~ demand + mean_temperature + solar_exposure + log(rainfall +1) + holiday + school_day + month, data = train, family = binomial)

summary(logit.out1)
```
```{r}

logistic.prob <- predict(logit.out1, type="response")
roc.out <- roc(train$high_RRP, logistic.prob, levels=c(FALSE, TRUE))
plot(roc.out, print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
```

As before, we proceed to remove the feature that had the highest P-value, which in this case is holiday.

```{r}
logit.out2 <- glm(high_RRP ~ demand + mean_temperature + school_day + month, data = train, family = binomial)

summary(logit.out2)
```

```{r}
logit.out3 <- glm(high_RRP ~ demand + mean_temperature + school_day, data = train, family = binomial)

summary(logit.out3)
```

It is possible to see that the general result is better than using the seasons. It is also noticeable how when changing the second model, removing the months, the deviance drops considerably. Because of that, we keep the second model (logit.out2). Finally, we make the ROC plot to see how much the area under the curve has changed with respect to the first model.

```{r}
logistic.prob <- predict(logit.out2, type="response")
roc.out <- roc(train$high_RRP, logistic.prob, levels=c(FALSE, TRUE))
plot(roc.out, print.auc=TRUE, legacy.axes=TRUE, xlab="False positive rate", ylab="True positive rate")
```

# 5 Model Evaluation


## 5.1 Linear Regression Evaluation

To evaluate the performance of our models, we will first get the MSE (Mean Squared Errors) of the test set by doing a simple test-train-split. We assign the 80 percent of the data to the training set and the rest of the data to the test set.

 

```{r}
###split the data into train and test and see their error(MSE)

set.seed(1)
n = dim(data)[1] #number of samples
ntrain = floor(dim(data)[1]*0.8)  #1678 samples for test(80 percent of the data)

train <- sample(1:n, size=ntrain, replace= FALSE) #index of training samples

# linear model with training data
mod.tot0.train <- lm(demand ~ poly(solar_exposure, 4) + 
                       poly(mean_temperature, 4) + season +
                       school_day , data=data , subset=train)

#predict the demand of the test data based on fitted model
y.pred <- predict(mod.tot0.train, newdata=data[-train, ])

# mean squared error on test data
MSE.val <- mean((data$demand[-train]-y.pred)^2)
MSE.val


```



Then also we use a 10-fold cross validation to have the better evaluation of our model and its error based on training data with 10 different parts of the data.
For training the data, we split the data to 10 folds. Each time we choose one of these folds as the test set and other nine parts as training set. After training the data and computing the MSE errors, we get an average of the errors achieved from 10 different test sets. At the end, the average amount of MSE error would be the best evaluation of the model's error.

```{r}
# k-fold cross-validation

set.seed(1)
k=10
folds <- sample(1:k, nrow(data), replace=TRUE)
#table(folds)

cv.errors <- matrix(NA,k,1)
colnames(cv.errors) <- 1


for(j in 1:k){
  best.fit <- lm(demand ~ poly(solar_exposure, 4) + poly(mean_temperature, 4) +
                   season + school_day, data=data[folds!=j,])
  test.mat <- model.matrix(demand ~ poly(solar_exposure, 4) +
                             poly(mean_temperature, 4) + season + 
                             school_day, data=data[folds==j,])
  y.pred <- predict(mod.tot0.train, newdata=data[folds==j,])
  cv.errors[j,1] <- mean( (data$demand[folds==j]-y.pred)^2)
  
}

mean.cv.errors <- apply(cv.errors,2,mean)
mean.cv.errors

```

The error values obtained by cross validation are less than the ones obtained by calculating the MSE, but not by much.

```{r, echo=FALSE}

cv.errors <- cv.errors[1:10,1]
tab <- matrix(cv.errors, ncol=1, byrow=TRUE)

#define column names and row names of matrix
colnames(tab) <- c("cv.errors")
rownames(tab) <- c("1","2","3","4","5","6","7","8","9","10")

tab <- as.table(tab)

tab

```


## 5.2 Logistic Regression Evaluation
In this part, the performance of the logistic regression model selected among those tested (second model using months) will be evaluated. The matrix evaluated in the test-set (623 samples) will be printed using the best threshold

```{r}

th <- coords(roc.out, "best")
probabilities <- logit.out2 %>% predict(test, type = "response")


trivial.pred <- rep(FALSE, 623)
logistic.pred <- rep(FALSE, 623)

logistic.pred[probabilities>th[1,1]] <- TRUE

CM <- table(logistic.pred, test$high_RRP)
CM
```

From the confusion matrix, an accuracy close to 56%, a specificity of 45.69%, and a sensitivity of 66%.


# 6 Conclusion

Based on the insights gained during the EDA part about the behavior of the different variables that have impact on RRP and demand, we build a regression model to predict the demand and determined that the best results are obtained by considering the "solar_exposure", "mean_temperature", "seasons" and "school_days" variables. As we saw, the behavior of the regression models had non linear correlation with two variables, "solar_exposure" and "mean_temperature". Furthermore, while performing the hypothesis test on variances in the EDA section, we could not find evidence that the variances were equal, because the data was very unbalanced. Thus, we could not use the t-test to check equality of the means. We couldn't find any other tests on the mean of the demand on different categories or any kind of ANOVA/ANCOVA test for seasons. 

Regarding logistic regression, the model that obtained the best results used the variables: "demand", "mean_temperature", "school_day", "month", and reported an area under the ROC curve equal to 0.608. The best threshold for this method was 0.43 and it is possible to see that the accuracy is quite low (56%), although the overall performance is quite low and should not be considered a good predictor of the RRP(due to the distribution of the data), the The model appears to have a decent sensitivity (66%), as reported in the confusion matrix in the previous section. 
